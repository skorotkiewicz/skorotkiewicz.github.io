<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2022/07 on Sebastian Korotkiewicz - Tech{{log}}</title><link>https://skorotkiewicz.github.io/archive/2022/07/</link><description>Recent content in 2022/07 on Sebastian Korotkiewicz - Tech{{log}}</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://skorotkiewicz.github.io/archive/2022/07/index.xml" rel="self" type="application/rss+xml"/><item><title>Start With Yolo V6</title><link>https://skorotkiewicz.github.io/techlog/start-with-yolov6/</link><pubDate>Sat, 02 Jul 2022 19:25:21 +0200</pubDate><guid>https://skorotkiewicz.github.io/techlog/start-with-yolov6/</guid><description>Create conda environment:
$ conda create -n yolo python=3.8 -y
Activate environment:
$ conda activate yolo
Download repo and install dependencies:
$ git clone https://github.com/meituan/YOLOv6 &amp;amp;&amp;amp; cd YOLOv6 $ pip install -r requirements.txt Download a pretrained model from the YOLOv6 release
Create new directory for frames:
$ mkdir input/
Split video to frames:
ffmpeg -i stepup.mp4 input/stepup_%04d.png
Start to dedect objects in frames:
python tools/infer.py --weights yolov6n.pt --source input/</description></item></channel></rss>